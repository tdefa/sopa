{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [
    "import spatialdata\n",
    "import sopa.segmentation\n",
    "import sopa.io"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a `SpatialData` object\n",
    "\n",
    "For this tutorial, we use a generated dataset. You can expect a total runtime of a few minutes.\n",
    "\n",
    "To load your own data, see the commented lines below, or read the [`sopa.io` API](../../api/io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "# The line below creates a toy dataset for this tutorial\n",
    "# To load your own data, such as MERSCOPE data, you can do `sdata = sopa.io.merscope(\"/path/to/region_0\")`\n",
    "# For more details, see https://gustaveroussy.github.io/sopa/api/io/\n",
    "sdata = sopa.io.uniform()\n",
    "\n",
    "sdata"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, we create the variables below that denotes the names of the image and transcripts that we want to use, as displayed in the `SpatialData` object above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "image_key = \"image\"\n",
    "points_key = \"transcripts\" # (ignore this for multiplex imaging)\n",
    "gene_column = \"genes\" # (optional) column of sdata[points_key] containing the gene names"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Cellpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we generate the bounding boxes of the patches on which Cellpose will be run. Here, the patches have a width and height of 1500 pixels and an overlap of 50 pixels. We advise bigger sizes for real datasets (see our default parameters in one of our [config files](https://github.com/gustaveroussy/sopa/tree/master/workflow/config)). On the toy dataset, this will generate **4** patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "patches = sopa.segmentation.Patches2D(sdata, image_key, patch_width=1200, patch_overlap=50)\n",
    "patches.write();"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following channels are available for segmentation. Choose one or two channels used by Cellpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "from sopa._sdata import get_spatial_image\n",
    "\n",
    "print(get_spatial_image(sdata, image_key).c.values)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we initialize the Cellpose model. Here, we run segmentation using DAPI only, and we set the cell diameter to be about `35` pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "channels = [\"DAPI\"]\n",
    "\n",
    "method = sopa.segmentation.methods.cellpose_patch(diameter=35, channels=channels, flow_threshold=2, cellprob_threshold=-6)\n",
    "segmentation = sopa.segmentation.StainingSegmentation(sdata, method, channels, min_area=2500)\n",
    "\n",
    "# The cellpose boundaries will be temporary saved here. You can choose a different path\n",
    "cellpose_temp_dir = \"tuto.zarr/.sopa_cache/cellpose\""
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential running\n",
    "\n",
    "If desired, you can run Cellpose sequentially, as in the lines below, but this is slower than the \"Parallel running\" section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "segmentation.write_patches_cells(cellpose_temp_dir)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel running\n",
    "\n",
    "Here, we show how to run Cellpose in parallel for all the patches. It's up to you to choose the way to parallelize it: for instance, if you have a Slurm cluster, you can run one job per patch.\n",
    "\n",
    "Below, we run segmentation on each patch, and save the results in a temporary directory (here, `tuto.zarr/.sopa_cache`).\n",
    "On this example, we performed a \"for-loop\", so you **should** paralellize this yourself using multiple jobs or multi-threading (see [this discussion](https://github.com/gustaveroussy/sopa/discussions/36) for more details). Note that you can also use our [Snakemake pipeline](https://gustaveroussy.github.io/sopa/tutorials/snakemake/) that will handle the parallelization for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "# parallelize this for loop yourself (or use the Snakemake pipeline)\n",
    "for patch_index in range(len(sdata['sopa_patches'])):\n",
    "    segmentation.write_patch_cells(cellpose_temp_dir, patch_index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resolving conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, you executed 4 times Cellpose (once per patch). Now, we need to resolve the conflict, i.e. where boundaries are overlapping due to segmentation on multiple patches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "cells = sopa.segmentation.StainingSegmentation.read_patches_cells(cellpose_temp_dir)\n",
    "cells = sopa.segmentation.shapes.solve_conflicts(cells)\n",
    "\n",
    "shapes_key = \"cellpose_boundaries\" # name of the key given to the cells in sdata.shapes\n",
    "\n",
    "sopa.segmentation.StainingSegmentation.add_shapes(sdata, cells, image_key, shapes_key)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Baysor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "shapes_key = \"baysor_boundaries\" # the name that we will give to the baysor \"shapes\""
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baysor needs a config to be executed. You can find official config examples [here](https://github.com/kharchenkolab/Baysor/tree/master/configs).\n",
    "\n",
    "You can also reuse the Baysor parameter we have defined for each machine, as in our [Snakemake config files](https://github.com/gustaveroussy/sopa/tree/master/workflow/config). Note that, our Snakemake config is a `.yaml` file, but the Baysor config should still be a `.toml` file.\n",
    "\n",
    "For this tutorial, we will use the config below. Instead of a dictionnary, you can also have a `.toml` file and provide `config_path` to the `patchify_transcripts` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "config = {\n",
    "    \"data\": {\n",
    "        \"force_2d\": True,\n",
    "        \"min_molecules_per_cell\": 10,\n",
    "        \"x\": \"x\",\n",
    "        \"y\": \"y\",\n",
    "        \"z\": \"z\",\n",
    "        \"gene\": \"genes\",\n",
    "        \"min_molecules_per_gene\": 0,\n",
    "        \"min_molecules_per_segment\": 3,\n",
    "        \"confidence_nn_id\": 6\n",
    "    },\n",
    "    \"segmentation\": {\n",
    "        \"scale\": 30,  # Important parameter: typical cell diameter, in microns (see our configs)\n",
    "        \"scale_std\": \"25%\",\n",
    "        \"prior_segmentation_confidence\": 0,\n",
    "        \"estimate_scale_from_centers\": False,\n",
    "        \"n_clusters\": 4,\n",
    "        \"iters\": 500,\n",
    "        \"n_cells_init\": 0,\n",
    "        \"nuclei_genes\": \"\",\n",
    "        \"cyto_genes\": \"\",\n",
    "        \"new_component_weight\": 0.2,\n",
    "        \"new_component_fraction\": 0.3\n",
    "    }\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we generate the bounding boxes of the patches on which Baysor will be run. Here, the patches have a width and height of 3000 microns and an overlap of 50 microns. We advise bigger sizes for real datasets (see our default parameters in one of our [config files](https://github.com/gustaveroussy/sopa/tree/master/workflow/config)). On the toy dataset, this will generate **1** patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "# The cellpose boundaries will be temporary saved here. You can choose a different path\n",
    "baysor_temp_dir = \"tuto.zarr/.sopa_cache/baysor\"\n",
    "\n",
    "patches = sopa.segmentation.Patches2D(sdata, points_key, patch_width=3000, patch_overlap=50)\n",
    "valid_indices = patches.patchify_transcripts(baysor_temp_dir, config=config)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run Baysor on each individual patch. It's up to you to choose the way to parallelize it: for instance, if you have a Slurm cluster, you can run one job per patch.\n",
    "\n",
    "Below, we run segmentation on each patch, and save the results in a temporary directory (here, `tuto.zarr/.sopa_cache/baysor`).\n",
    "On this example, we performed a \"for-loop\", so you **should** paralellize this yourself using multiple jobs or multi-threading (see [this discussion](https://github.com/gustaveroussy/sopa/discussions/36) for more details). Note that you can also use our [Snakemake pipeline](https://gustaveroussy.github.io/sopa/tutorials/snakemake/) that will handle the parallelization for you.\n",
    "\n",
    "> NB: depending on you Baysor installation, you may need to update the `baysor_executable_path` variable to locate the Baysor binary executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "import subprocess\n",
    "\n",
    "baysor_executable_path = \"~/.julia/bin/baysor\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "for patch_index in valid_indices:\n",
    "    command = f\"\"\"\n",
    "    cd {baysor_temp_dir}/{patch_index}\n",
    "    {baysor_executable_path} run --save-polygons GeoJSON -c config.toml transcripts.csv\n",
    "    \"\"\"\n",
    "    subprocess.run(command, shell=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, you executed 4 times Baysor (once per patch). Now, we need to resolve the conflict, i.e. where boundaries are overlapping due to segmentation on multiple patches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sopa.segmentation.baysor.resolve import resolve\n",
    "\n",
    "resolve(sdata, baysor_temp_dir, gene_column, min_area=500)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate\n",
    "\n",
    "This **mandatory** step turns the data into an `AnnData` object. We can count the transcript inside each cell, and/or average each channel intensity inside each cell boundary.\n",
    "\n",
    "> NB: Baysor already counts the transcripts inside each cell to create a cell-by-gene table, so you don't need to provide `gene_column`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "aggregator = sopa.segmentation.Aggregator(sdata, image_key=image_key, shapes_key=shapes_key)\n",
    "\n",
    "aggregator.compute_table(gene_column=gene_column, average_intensities=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "sdata"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `sdata.tables[\"table\"]` is an `AnnData` object.\n",
    "- If you count the transcripts, then `adata.X` are the raw counts\n",
    "- If you average the channel intensities, then `adata.X` are the channels intensities\n",
    "- If you both count the transcript and average the intensities, then `adata.X` are the raw counts, and `adata.obsm[\"intensities\"]` are the channels intensities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation\n",
    "\n",
    "#### Option 1: Transcript-based (Tangram)\n",
    "\n",
    "[Tangram](https://github.com/broadinstitute/Tangram) is a transcript-based annotation that uses an annotated single-cell reference. Let's suppose your reference `AnnData` object is stored in a file called `adata_reference.h5ad` (preferably, keep raw counts), and the cell type is in `adata.obs[\"cell_type\"]`. Then, you can annotate your spatial data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "from sopa.annotation.tangram import tangram_annotate\n",
    "import anndata"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "adata_reference = anndata.read_h5ad(\"adata_reference.h5ad\")\n",
    "\n",
    "tangram_annotate(sdata, adata_reference, \"cell_type\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Staining-based\n",
    "For now, our fluorescence-based annotation is very simple. We provide a dictionary where a channel is associated with a population. Then, each cell is associated with the cell type whose corresponding channel is the brightest (according to a certain Z-score). In this tutorial example, we can annotate Tumoral cells, T cells, and B cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "from sopa.annotation import higher_z_score\n",
    "\n",
    "marker_cell_dict = {\n",
    "    \"CK\": \"Tumoral cell\",\n",
    "    \"CD20\": \"B cell\",\n",
    "    \"CD3\": \"T cell\"\n",
    "}\n",
    "\n",
    "higher_z_score(sdata.tables[\"table\"], marker_cell_dict)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline report\n",
    "You can optionally create an HTML report of the pipeline run (in the example below, we save it under `report.html`). It contains some quality controls for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "sopa.io.write_report(\"report.html\", sdata)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the Xenium Explorer\n",
    "\n",
    "The Xenium Explorer is a software developed by 10X Genomics for visualizing spatial data, and it can be downloaded freely [here](https://www.10xgenomics.com/support/software/xenium-explorer/latest). Sopa allows the conversion to the Xenium Explorer, whatever the type of spatial data you worked on. It will create some files under a new `tuto.explorer` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "sopa.io.write(\"tuto.explorer\", sdata, image_key, points_key=points_key, gene_column=gene_column)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have downloaded the Xenium Explorer, you can now open the results in the explorer: `open tuto.explorer/experiment.xenium` (if using a Unix operating system), or double-click on the latter file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With `spatialdata-plot`\n",
    "[`spatialdata-plot`](https://github.com/scverse/spatialdata-plot) library is a static plotting library for `SpatialData` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "import spatialdata_plot"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "source": [
    "sdata\\\n",
    "    .pl.render_points(size=0.01, color=\"r\")\\\n",
    "    .pl.render_images()\\\n",
    "    .pl.render_shapes(shapes_key, outline=True, fill_alpha=0, outline_color=\"w\")\\\n",
    "    .pl.show(\"global\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your `SpatialData` object\n",
    "\n",
    "You can save your `SpatialData` object for later use. This will create a `.zarr` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "sdata.write(\"tuto.zarr\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then open the data with `spatialdata`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import spatialdata\n",
    "\n",
    "spatialdata.read_zarr(\"tuto.zarr\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further analyses\n",
    "\n",
    "- You can read [this tutorial](../spatial) on spatial statistic and geometric analysis.\n",
    "- You can use [Squidpy](https://squidpy.readthedocs.io/en/latest/index.html) which operates on both the `SpatialData` object or the `AnnData` object, or use other tools of the `scverse` ecosystem such as [`Scanpy`](https://scanpy.readthedocs.io/en/stable/index.html).\n",
    "- You can also try the CLI or the Snakemake pipeline of Sopa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sopa-hDHgkEug-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
